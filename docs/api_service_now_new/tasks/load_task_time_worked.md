# LoadTaskTimeWorked

## Vis√£o Geral

A task `LoadTaskTimeWorked` extrai registros de tempo trabalhado em tasks do ServiceNow. Estes dados s√£o essenciais para an√°lises de produtividade, cobran√ßa de horas, e m√©tricas de efici√™ncia das equipes.

## Caracter√≠sticas

- **Tipo**: Task de Incidents (com per√≠odo)
- **Modelo**: `TaskTimeWorked`
- **Filtro Principal**: `sys_created_on` (data de cria√ß√£o do registro)
- **Estrat√©gia de Carga**: DELETE + INSERT (transacional)
- **Relacionamento**: Conecta com `IncidentTask` via campo `task`

## Implementa√ß√£o

### Classe Principal

```python
class LoadTaskTimeWorked(MixinGetDataset, Pipeline):
    def __init__(self, start_date: str, end_date: str):
        self.start_date = start_date  # YYYY-MM-DD
        self.end_date = end_date      # YYYY-MM-DD
        super().__init__()
```

### Query ServiceNow

```python
query = f"sys_created_on>={self.start_date} 00:00:00^sys_created_on<={self.end_date} 23:59:59"
```

**Caracter√≠sticas da Query**:
- Filtra por `sys_created_on` (quando o registro de tempo foi criado)
- **N√£o usa filtro de grupo** espec√≠fico (diferente de outras tasks)
- Captura todos os registros de tempo do per√≠odo

## Estrutura de Dados

### Campos Principais

O modelo `TaskTimeWorked` inclui:

**Identifica√ß√£o**:
- `sys_id` (PK) - ID √∫nico do registro de tempo
- `task` - Refer√™ncia √† task (sys_id)

**Tempo Trabalhado**:
- `time_spent` - Tempo gasto (em horas, formato decimal)
- `work_start` - Data/hora de in√≠cio do trabalho
- `work_end` - Data/hora de fim do trabalho

**Descri√ß√£o**:
- `short_description` - Descri√ß√£o breve do trabalho realizado
- `work_notes` - Notas detalhadas do trabalho

**Usu√°rio**:
- `created_by` - Quem registrou o tempo
- `user` - Usu√°rio que executou o trabalho (pode ser diferente do created_by)

**Auditoria**:
- `sys_created_on`, `sys_created_by`
- `sys_updated_on`, `sys_updated_by`

### Exemplo de Registro

```json
{
  "sys_id": "time123abc",
  "task": "task456def", 
  "time_spent": "2.5",
  "work_start": "2025-01-20 09:00:00",
  "work_end": "2025-01-20 11:30:00",
  "short_description": "Configura√ß√£o de firewall",
  "work_notes": "Configurei as regras de firewall conforme solicitado. Testei conectividade e documentei as mudan√ßas.",
  "created_by": "usr789ghi",
  "user": "usr789ghi",
  "sys_created_on": "2025-01-20 11:35:00"
}
```

## Relacionamentos

### Com IncidentTask

```python
# Buscar tempo total trabalhado em uma task
task = IncidentTask.objects.get(number="TASK0001234")
time_records = TaskTimeWorked.objects.filter(task=task.sys_id)

total_hours = sum([
    float(record.time_spent) for record in time_records 
    if record.time_spent
])

print(f"Tempo total na task {task.number}: {total_hours}h")
```

### Com Incident (via Task)

```python
# Tempo total trabalhado em um incident (soma de todas as tasks)
incident = Incident.objects.get(number="INC0001234")

# Busca todas as tasks do incident
incident_tasks = IncidentTask.objects.filter(parent=incident.sys_id)

total_incident_time = 0
for task in incident_tasks:
    task_time_records = TaskTimeWorked.objects.filter(task=task.sys_id)
    task_total = sum([
        float(record.time_spent or 0) for record in task_time_records
    ])
    total_incident_time += task_total

print(f"Tempo total no incident {incident.number}: {total_incident_time}h")
```

### Com Usu√°rios

```python
# Produtividade por usu√°rio
from django.db.models import Sum
from django.db import connection

user_productivity = TaskTimeWorked.objects.filter(
    sys_created_on__date='2025-01-20'
).values('created_by').annotate(
    total_time=Sum('time_spent'),
    task_count=Count('task', distinct=True)
).order_by('-total_time')

for record in user_productivity:
    if record['created_by']:
        user = SysUser.objects.filter(sys_id=record['created_by']).first()
        user_name = user.name if user else f"ID: {record['created_by']}"
        avg_time_per_task = record['total_time'] / record['task_count'] if record['task_count'] else 0
        
        print(f"{user_name}:")
        print(f"  Total: {record['total_time']:.1f}h")
        print(f"  Tasks: {record['task_count']}")
        print(f"  M√©dia/task: {avg_time_per_task:.1f}h")
```

## An√°lises e M√©tricas

### 1. Produtividade Di√°ria

```python
def daily_productivity_report(date_target):
    """Relat√≥rio de produtividade di√°ria por usu√°rio"""
    
    daily_stats = TaskTimeWorked.objects.filter(
        sys_created_on__date=date_target
    ).aggregate(
        total_hours=Sum('time_spent'),
        total_records=Count('sys_id'),
        unique_users=Count('created_by', distinct=True),
        unique_tasks=Count('task', distinct=True)
    )
    
    # Top 10 usu√°rios por horas trabalhadas
    top_users = TaskTimeWorked.objects.filter(
        sys_created_on__date=date_target
    ).values('created_by').annotate(
        hours=Sum('time_spent')
    ).order_by('-hours')[:10]
    
    return {
        'summary': daily_stats,
        'top_users': list(top_users)
    }
```

### 2. Efici√™ncia por Tipo de Task

```python
def task_efficiency_analysis():
    """Analisa efici√™ncia por tipo de task baseado em descri√ß√µes"""
    
    # Categoriza tasks por palavras-chave
    categories = {
        'firewall': ['firewall', 'iptables', 'security'],
        'server': ['server', 'servidor', 'vm'], 
        'network': ['network', 'rede', 'switch', 'router'],
        'database': ['database', 'db', 'sql', 'mysql']
    }
    
    efficiency_data = {}
    
    for category, keywords in categories.items():
        # Tasks que cont√™m palavras-chave
        task_filter = Q()
        for keyword in keywords:
            task_filter |= Q(short_description__icontains=keyword)
        
        time_records = TaskTimeWorked.objects.filter(
            task_filter,
            sys_created_on__date__gte=date.today() - timedelta(days=30)
        )
        
        if time_records.exists():
            stats = time_records.aggregate(
                avg_time=Avg('time_spent'),
                total_time=Sum('time_spent'),
                record_count=Count('sys_id'),
                unique_tasks=Count('task', distinct=True)
            )
            
            efficiency_data[category] = {
                'avg_time_per_record': stats['avg_time'] or 0,
                'total_time': stats['total_time'] or 0,
                'avg_time_per_task': (stats['total_time'] / stats['unique_tasks']) if stats['unique_tasks'] else 0,
                'record_count': stats['record_count'],
                'task_count': stats['unique_tasks']
            }
    
    return efficiency_data
```

### 3. An√°lise de Overtime

```python
def overtime_analysis(date_start, date_end):
    """Identifica poss√≠vel overtime baseado em hor√°rios"""
    
    # Registros fora do hor√°rio comercial (antes 8h ou ap√≥s 18h)
    overtime_records = TaskTimeWorked.objects.extra(
        where=[
            "EXTRACT(hour FROM work_start::timestamp) < 8 OR EXTRACT(hour FROM work_end::timestamp) > 18"
        ]
    ).filter(
        sys_created_on__date__range=[date_start, date_end],
        work_start__isnull=False,
        work_end__isnull=False
    )
    
    overtime_by_user = overtime_records.values('created_by').annotate(
        overtime_hours=Sum('time_spent'),
        overtime_sessions=Count('sys_id')
    ).order_by('-overtime_hours')
    
    return list(overtime_by_user)
```

## Performance

### M√©tricas T√≠picas

| M√©trica | Valor T√≠pico | Observa√ß√µes |
|---------|--------------|-------------|
| **Volume Di√°rio** | 200-1000 registros | Depende da disciplina das equipes |
| **Tempo M√©dio** | 1-3 minutos | Query simples, sem dot-walk |
| **Ratio Time/Task** | 0.5-2.0 | Registros de tempo por task |
| **Horas M√©dias/Registro** | 1-4 horas | Vari√°vel por tipo de trabalho |

### Caracter√≠sticas da Query

```python
# ‚úÖ Query simples e r√°pida
query = "sys_created_on>=2025-01-20 00:00:00^sys_created_on<=2025-01-20 23:59:59"

# N√£o usa filtros de grupo (diferente de outras tasks)
# Captura TODOS os registros de tempo do per√≠odo
```

**Vantagem**: Mais r√°pida que tasks com dot-walk ou filtros complexos

**Cuidado**: Pode capturar registros de grupos n√£o-Vita

## Valida√ß√µes e Qualidade

### 1. Consist√™ncia Temporal

```python
def validate_time_consistency():
    """Valida consist√™ncia entre work_start, work_end e time_spent"""
    
    inconsistent = []
    
    time_records = TaskTimeWorked.objects.filter(
        work_start__isnull=False,
        work_end__isnull=False,
        time_spent__isnull=False,
        sys_created_on__date=date.today()
    )
    
    for record in time_records:
        try:
            start = datetime.fromisoformat(record.work_start.replace('Z', '+00:00'))
            end = datetime.fromisoformat(record.work_end.replace('Z', '+00:00'))
            
            duration_hours = (end - start).total_seconds() / 3600
            reported_hours = float(record.time_spent)
            
            # Diferen√ßa > 15 minutos √© suspeita
            if abs(duration_hours - reported_hours) > 0.25:
                inconsistent.append({
                    'sys_id': record.sys_id,
                    'calculated': duration_hours,
                    'reported': reported_hours,
                    'difference': abs(duration_hours - reported_hours)
                })
                
        except (ValueError, TypeError):
            continue
    
    return inconsistent
```

### 2. Registros √ìrf√£os

```python
def find_orphaned_time_records():
    """Encontra registros de tempo sem task v√°lida"""
    
    orphaned = TaskTimeWorked.objects.extra(
        where=["task NOT IN (SELECT sys_id FROM incident_task)"]
    ).filter(
        sys_created_on__date__gte=date.today() - timedelta(days=7)
    )
    
    if orphaned.exists():
        logger.warning(f"Registros de tempo √≥rf√£os: {orphaned.count()}")
        
        # Detalhes dos √≥rf√£os
        for record in orphaned[:10]:  # Primeiros 10
            logger.debug(f"√ìrf√£o: {record.sys_id} ‚Üí Task: {record.task}")
    
    return orphaned.count()
```

## Execu√ß√£o

### Standalone

```python
task = LoadTaskTimeWorked(
    start_date="2025-01-20",
    end_date="2025-01-20"
)

with task as loader:
    result = loader.run()
    
print(f"Registros de tempo: {result['n_inserted']}")
print(f"Dura√ß√£o: {result['duration']}s")

# An√°lise r√°pida dos dados carregados
today_records = TaskTimeWorked.objects.filter(sys_created_on__date='2025-01-20')
total_hours = sum([float(r.time_spent or 0) for r in today_records])
unique_users = today_records.values('created_by').distinct().count()

print(f"Total de horas registradas: {total_hours:.1f}h")
print(f"Usu√°rios √∫nicos: {unique_users}")
```

### Em Paralelo (LoadIncidentsView)

Executa simultaneamente com outras 3 tasks de incidents:

```python
heavy_tasks = [
    ("load_incidents_opened", LoadIncidentsOpened),
    ("load_incident_sla", LoadIncidentSla),
    ("load_task_time_worked", LoadTaskTimeWorked),  # Esta task
    ("load_incident_task", LoadIncidentTask),
]

# 4 threads paralelas
threads = []
for name, cls in heavy_tasks:
    th = threading.Thread(
        target=_run_task,
        args=(name, cls, start_date, end_date, results, errors),
        daemon=True
    )
    th.start()
    threads.append(th)
```

## Monitoramento

### KPIs de Tempo Trabalhado

```python
def time_tracking_kpis(target_date):
    """KPIs de tracking de tempo para dashboard"""
    
    records = TaskTimeWorked.objects.filter(sys_created_on__date=target_date)
    
    if not records.exists():
        return {'error': 'Nenhum registro de tempo encontrado'}
    
    # Estat√≠sticas b√°sicas
    total_records = records.count()
    total_hours = sum([float(r.time_spent or 0) for r in records])
    unique_users = records.values('created_by').distinct().count()
    unique_tasks = records.values('task').distinct().count()
    
    # Distribui√ß√£o de horas
    hours_list = [float(r.time_spent) for r in records if r.time_spent]
    avg_hours = sum(hours_list) / len(hours_list) if hours_list else 0
    
    # Usu√°rios mais produtivos
    top_users = records.values('created_by').annotate(
        hours=Sum('time_spent')
    ).order_by('-hours')[:5]
    
    return {
        'total_records': total_records,
        'total_hours': round(total_hours, 1),
        'unique_users': unique_users,
        'unique_tasks': unique_tasks,
        'avg_hours_per_record': round(avg_hours, 2),
        'records_per_user': round(total_records / unique_users, 1) if unique_users else 0,
        'hours_per_user': round(total_hours / unique_users, 1) if unique_users else 0,
        'top_users': list(top_users)
    }
```

### Alertas de Qualidade

```python
def quality_alerts(target_date):
    """Alertas de qualidade dos dados de tempo"""
    
    alerts = []
    records = TaskTimeWorked.objects.filter(sys_created_on__date=target_date)
    
    # 1. Volume muito baixo
    if records.count() < 50:  # Threshold ajust√°vel
        alerts.append({
            'type': 'low_volume',
            'message': f'Volume baixo de registros: {records.count()}'
        })
    
    # 2. Muitos registros sem tempo
    no_time = records.filter(Q(time_spent__isnull=True) | Q(time_spent=''))
    if no_time.count() > records.count() * 0.1:  # >10%
        alerts.append({
            'type': 'missing_time',
            'message': f'{no_time.count()} registros sem tempo informado'
        })
    
    # 3. Registros com tempo excessivo
    high_time = records.extra(
        where=["CAST(time_spent AS FLOAT) > 12"]  # >12 horas
    )
    if high_time.exists():
        alerts.append({
            'type': 'excessive_time',
            'message': f'{high_time.count()} registros com >12h'
        })
    
    # 4. Falta de descri√ß√£o
    no_desc = records.filter(
        Q(short_description__isnull=True) | 
        Q(short_description='')
    )
    if no_desc.count() > records.count() * 0.2:  # >20%
        alerts.append({
            'type': 'missing_description',
            'message': f'{no_desc.count()} registros sem descri√ß√£o'
        })
    
    return alerts
```

## Troubleshooting

### Problemas Comuns

**1. Volume inconsistente**
```
Situa√ß√£o: Alguns dias com 0 registros, outros com centenas
Causa: Equipes n√£o registram tempo consistentemente
Solu√ß√£o: Treinamento e pol√≠ticas de time tracking
```

**2. Registros √≥rf√£os**
```
Situa√ß√£o: time_worked.task n√£o existe em incident_task
Causa: Tasks deletadas ap√≥s registros de tempo
Investiga√ß√£o: Validar integridade referencial
```

**3. Tempos irreais**
```
Situa√ß√£o: Registros com 24+ horas ou 0.1 horas
Causa: Erros de entrada de dados
Solu√ß√£o: Valida√ß√µes no ServiceNow
```

### Debug de Dados

```python
# An√°lise de qualidade dos dados carregados
def analyze_loaded_data(target_date):
    """An√°lise detalhada dos dados carregados"""
    
    records = TaskTimeWorked.objects.filter(sys_created_on__date=target_date)
    
    print(f"üìä An√°lise LoadTaskTimeWorked - {target_date}")
    print(f"Total de registros: {records.count()}")
    
    # Distribui√ß√£o de tempo
    times = [float(r.time_spent) for r in records if r.time_spent]
    if times:
        print(f"Tempo total: {sum(times):.1f}h")
        print(f"Tempo m√©dio: {sum(times)/len(times):.2f}h")
        print(f"Tempo m√≠n/m√°x: {min(times):.2f}h / {max(times):.2f}h")
    
    # Top tasks por tempo
    top_tasks = records.values('task').annotate(
        total_time=Sum('time_spent')
    ).order_by('-total_time')[:5]
    
    print(f"\nTop 5 tasks por tempo:")
    for item in top_tasks:
        task = IncidentTask.objects.filter(sys_id=item['task']).first()
        task_name = task.number if task else f"ID: {item['task'][:8]}..."
        print(f"  {task_name}: {item['total_time']}h")
```

Esta task √© crucial para an√°lises de produtividade, cobran√ßa de horas e otimiza√ß√£o de processos, fornecendo insights detalhados sobre como o tempo √© gasto na resolu√ß√£o de incidents.