# upsert_by_sys_id()

## Vis√£o Geral

A fun√ß√£o `upsert_by_sys_id()` implementa uma estrat√©gia inteligente de inser√ß√£o/atualiza√ß√£o de dados baseada no campo `sys_id` do ServiceNow. Diferente de um DELETE + INSERT simples, ela preserva timestamps ETL e atualiza apenas registros que realmente mudaram.

## Assinatura

```python
@transaction.atomic
def upsert_by_sys_id(
    dataset: pl.DataFrame, 
    model, 
    log: Optional[Dict] = None
) -> None:
```

## Caracter√≠sticas Principais

### Estrat√©gia Inteligente
- **Preserva ETL Timestamps**: `etl_created_at` n√£o √© sobrescrito
- **Update Seletivo**: Apenas registros modificados s√£o atualizados
- **Performance**: Evita DELETE/INSERT desnecess√°rios
- **Transacional**: Rollback autom√°tico em caso de erro

### Compara√ß√£o com load()

| Aspecto | `self.load()` | `upsert_by_sys_id()` |
|---------|---------------|----------------------|
| **Estrat√©gia** | DELETE + INSERT | UPDATE + INSERT |
| **Timestamps ETL** | Sempre recriados | Preservados |
| **Performance** | Mais lento | Mais r√°pido |
| **Uso** | Tasks de incidents | Tasks de configura√ß√µes |
| **Consist√™ncia** | Total (remove √≥rf√£os) | Parcial (n√£o remove) |

## Algoritmo Detalhado

### 1. Valida√ß√£o e Prepara√ß√£o

```python
# Converte dataset para lista de dicion√°rios
if isinstance(dataset, pl.DataFrame):
    if dataset.is_empty():
        return
    rows = dataset.to_dicts()
elif isinstance(dataset, list):
    rows = dataset
else:
    try:
        rows = list(dataset)
    except Exception:
        rows = []

if not rows:
    return
```

### 2. Filtragem de Campos

```python
# Obt√©m campos v√°lidos do modelo Django
field_names = {f.name for f in model._meta.fields}
pk_name = model._meta.pk.name

# Filtra apenas registros com sys_id v√°lido
processed = []
for record in rows:
    if not record:
        continue
    
    # Apenas campos que existem no modelo
    filtered_record = {
        key: (value if value != "" else None)
        for key, value in record.items()
        if key in field_names
    }
    
    if filtered_record.get("sys_id"):
        processed.append(filtered_record)
```

### 3. Identifica√ß√£o de Existentes

```python
# Busca registros que j√° existem no banco
existing = {
    obj.sys_id: obj
    for obj in model.objects.filter(
        sys_id__in=[record["sys_id"] for record in processed]
    )
}
```

### 4. Separa√ß√£o em Opera√ß√µes

```python
to_create = []  # Novos registros
to_update = []  # Registros existentes

for record in processed:
    sys_id = record["sys_id"]
    
    if sys_id in existing:
        # Registro existe: UPDATE
        obj = existing[sys_id]
        for key, value in record.items():
            if key not in (pk_name,):  # N√£o atualiza PK
                setattr(obj, key, value)
        to_update.append(obj)
    else:
        # Registro novo: INSERT
        to_create.append(model(**record))
```

### 5. Execu√ß√£o Bulk

```python
created_count = 0

# Bulk CREATE
if to_create:
    created_count = len(model.objects.bulk_create(to_create, batch_size=1000))

# Bulk UPDATE
if to_update:
    update_fields = [
        field for field in field_names 
        if field not in (pk_name, "sys_id")
    ]
    
    if update_fields:
        try:
            model.objects.bulk_update(to_update, update_fields, batch_size=1000)
        except Exception:
            # Fallback: update individual
            for obj in to_update:
                try:
                    obj.save(update_fields=update_fields)
                except Exception:
                    logger.exception(f"Falha update individual sys_id={obj.sys_id}")

# Log de resultados
if isinstance(log, dict):
    log["n_inserted"] = log.get("n_inserted", 0) + created_count
```

## Vantagens

### 1. Preserva√ß√£o de Timestamps

**Com load() (DELETE+INSERT)**:
```python
# Primeiro load
contract = ContractSla.objects.get(sys_id="abc123")
print(contract.etl_created_at)  # 2025-01-15 10:00:00

# Segundo load (mesmo contrato inalterado)
# DELETE + INSERT
contract = ContractSla.objects.get(sys_id="abc123") 
print(contract.etl_created_at)  # 2025-01-20 14:30:00 ‚Üê PERDEU HIST√ìRICO
```

**Com upsert_by_sys_id()**:
```python
# Primeiro load
contract = ContractSla.objects.get(sys_id="abc123")
print(contract.etl_created_at)  # 2025-01-15 10:00:00

# Segundo load (contrato inalterado)
# Nenhuma opera√ß√£o (n√£o existe em to_update)
contract = ContractSla.objects.get(sys_id="abc123")
print(contract.etl_created_at)  # 2025-01-15 10:00:00 ‚Üê PRESERVADO
```

### 2. Performance Superior

```python
# Cen√°rio: 100 contratos SLA, apenas 5 modificados

# load(): DELETE + INSERT
# - DELETE: 100 registros
# - INSERT: 100 registros  
# Total: 200 opera√ß√µes de DB

# upsert_by_sys_id():
# - INSERT: 0 novos
# - UPDATE: 5 modificados
# Total: 5 opera√ß√µes de DB (40x mais r√°pido!)
```

### 3. Auditoria Detalhada

```python
def analyze_upsert_impact(before_count, after_count, log):
    """Analisa impacto do upsert"""
    
    created = log.get("n_inserted", 0)
    updated = after_count - before_count + created
    unchanged = before_count - updated
    
    print(f"üìä Upsert Analysis:")
    print(f"   ‚úÖ Novos: {created}")
    print(f"   üîÑ Modificados: {updated}")  
    print(f"   ‚ö° Inalterados: {unchanged}")
    print(f"   üìà Taxa de mudan√ßa: {(created + updated) / (after_count or 1) * 100:.1f}%")
```

## Casos de Uso

### 1. Configura√ß√µes Est√°ticas

**Ideal para**:
- `ContractSla`: Contratos raramente mudam
- `Groups`: Grupos organizacionais est√°veis
- `SysCompany`: Empresas raramente criadas/modificadas
- `SysUser`: Usu√°rios relativamente est√°ticos

```python
# LoadContractSla
def run(self) -> Dict:
    self.extract_and_transform_dataset()
    upsert_by_sys_id(dataset=self.dataset, model=ContractSla, log=self.log)
    return self.log
```

### 2. Master Data Management

```python
# Manter dados de refer√™ncia atualizados sem perder hist√≥rico
def sync_master_data():
    """Sincroniza dados mestre preservando auditoria"""
    
    # Busca dados atuais do ServiceNow
    current_groups = paginate("sys_user_group", params={"sysparm_query": "active=true"})
    dataset = pl.DataFrame(current_groups)
    
    # Conta registros antes
    before = Groups.objects.count()
    
    # Upsert
    log = {}
    upsert_by_sys_id(dataset, Groups, log)
    
    # An√°lise p√≥s-upsert
    after = Groups.objects.count()
    print(f"Grupos: {before} ‚Üí {after} (+{log.get('n_inserted', 0)} novos)")
```

### 3. Incremental Updates

```python
def incremental_user_sync():
    """Atualiza apenas usu√°rios modificados recentemente"""
    
    # √öltima sincroniza√ß√£o
    last_sync = ServiceNowExecutionLog.objects.filter(
        execution_type='users_sync',
        status='success'
    ).order_by('-started_at').first()
    
    since = last_sync.started_at if last_sync else "2025-01-01"
    
    # Apenas usu√°rios modificados
    users = paginate("sys_user", params={
        "sysparm_query": f"sys_updated_on>={since}",
    })
    
    dataset = pl.DataFrame(users)
    upsert_by_sys_id(dataset, SysUser, log={})
```

## Limita√ß√µes

### 1. N√£o Remove √ìrf√£os

```python
# Cen√°rio: Contrato deletado no ServiceNow
# mas ainda existe no banco local

# load() removeria (DELETE antes do INSERT)
# upsert_by_sys_id() mant√©m (n√£o h√° DELETE)

# Solu√ß√£o: limpeza peri√≥dica manual
def cleanup_orphaned_contracts():
    """Remove contratos que n√£o existem mais no ServiceNow"""
    
    # Busca todos os contratos ativos no ServiceNow
    current_contracts = set()
    servicenow_contracts = paginate("contract_sla", params={"sysparm_query": "active=true"})
    current_contracts.update(c["sys_id"] for c in servicenow_contracts)
    
    # Identifica √≥rf√£os
    local_contracts = set(ContractSla.objects.values_list('sys_id', flat=True))
    orphans = local_contracts - current_contracts
    
    if orphans:
        logger.warning(f"Removendo {len(orphans)} contratos √≥rf√£os")
        ContractSla.objects.filter(sys_id__in=orphans).delete()
```

### 2. N√£o Detecta Mudan√ßas de Conte√∫do

```python
# upsert_by_sys_id() sempre atualiza campos, mesmo se valor n√£o mudou
# Poss√≠vel otimiza√ß√£o futura: comparar valores antes de atualizar

def smart_upsert_by_sys_id(dataset, model, log=None):
    """Upsert que compara valores antes de atualizar"""
    
    # ... c√≥digo similar at√© separa√ß√£o de opera√ß√µes ...
    
    smart_updates = []
    for record in processed:
        sys_id = record["sys_id"]
        if sys_id in existing:
            obj = existing[sys_id]
            has_changes = False
            
            # Compara cada campo
            for key, new_value in record.items():
                current_value = getattr(obj, key, None)
                if str(current_value) != str(new_value):
                    setattr(obj, key, new_value)
                    has_changes = True
            
            # Apenas adiciona se realmente mudou
            if has_changes:
                smart_updates.append(obj)
    
    # Bulk update apenas dos modificados
    if smart_updates:
        model.objects.bulk_update(smart_updates, update_fields, batch_size=1000)
```

### 3. Memory Usage

```python
# Para datasets muito grandes, carrega todos em mem√≥ria
existing = {obj.sys_id: obj for obj in model.objects.filter(...)}

# Otimiza√ß√£o para datasets grandes
def chunked_upsert(dataset, model, chunk_size=1000):
    """Upsert em chunks para economizar mem√≥ria"""
    
    if isinstance(dataset, pl.DataFrame):
        rows = dataset.to_dicts()
    else:
        rows = list(dataset)
    
    for i in range(0, len(rows), chunk_size):
        chunk = rows[i:i+chunk_size]
        chunk_df = pl.DataFrame(chunk)
        upsert_by_sys_id(chunk_df, model)
```

## Monitoramento e M√©tricas

### Tracking de Mudan√ßas

```python
def track_upsert_patterns():
    """Monitora padr√µes de mudan√ßas nos dados"""
    
    # An√°lise de frequ√™ncia de updates
    recent_updates = {}
    models = [ContractSla, Groups, SysCompany, SysUser]
    
    for model in models:
        recent = model.objects.filter(
            etl_updated_at__gte=timezone.now() - timedelta(hours=24)
        ).count()
        
        total = model.objects.count()
        update_rate = (recent / total * 100) if total > 0 else 0
        
        recent_updates[model.__name__] = {
            'recent': recent,
            'total': total,
            'rate': update_rate
        }
    
    return recent_updates

# Alertas baseados em padr√µes
patterns = track_upsert_patterns()
for model_name, stats in patterns.items():
    if stats['rate'] > 50:  # >50% dos registros modificados
        send_alert(f"{model_name}: Taxa alta de mudan√ßas ({stats['rate']:.1f}%)")
```

### Performance Metrics

```python
def benchmark_upsert_vs_load():
    """Compara performance upsert vs load"""
    
    import time
    
    # Dados de teste
    test_contracts = paginate("contract_sla", params={"sysparm_limit": "100"})
    dataset = pl.DataFrame(test_contracts)
    
    # Teste load() tradicional
    start = time.time()
    # Simula load (sem DELETE real para n√£o impactar dados)
    ContractSla.objects.bulk_create([ContractSla(**r) for r in dataset.to_dicts()[:10]], ignore_conflicts=True)
    load_time = time.time() - start
    
    # Teste upsert  
    start = time.time()
    log = {}
    upsert_by_sys_id(dataset, ContractSla, log)
    upsert_time = time.time() - start
    
    print(f"Load time: {load_time:.2f}s")
    print(f"Upsert time: {upsert_time:.2f}s") 
    print(f"Speedup: {load_time / upsert_time:.1f}x")
    print(f"New records: {log.get('n_inserted', 0)}")
```

## Error Handling

### Bulk Update Fallback

```python
# O c√≥digo j√° implementa fallback autom√°tico
try:
    model.objects.bulk_update(to_update, update_fields, batch_size=1000)
except Exception:
    # Fallback: update individual
    for obj in to_update:
        try:
            obj.save(update_fields=update_fields)
        except Exception:
            logging.exception(f"Falha update individual sys_id={getattr(obj, 'sys_id', None)}")
```

### Validation Errors

```python
def safe_upsert_by_sys_id(dataset, model, log=None):
    """Upsert com valida√ß√£o de dados"""
    
    # Pre-valida√ß√£o de dados obrigat√≥rios
    valid_records = []
    invalid_count = 0
    
    for record in processed:
        try:
            # Testa cria√ß√£o do objeto (sem salvar)
            test_obj = model(**record)
            test_obj.full_clean()  # Valida constraints
            valid_records.append(record)
        except Exception as e:
            logger.warning(f"Record inv√°lido sys_id={record.get('sys_id')}: {e}")
            invalid_count += 1
    
    if invalid_count > 0:
        logger.warning(f"Ignorados {invalid_count} registros inv√°lidos")
    
    # Processa apenas registros v√°lidos
    # ... resto do c√≥digo normal ...
```

Esta fun√ß√£o √© essencial para manter dados de configura√ß√£o atualizados de forma eficiente, preservando auditoria e minimizando opera√ß√µes desnecess√°rias no banco de dados.